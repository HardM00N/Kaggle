{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Contents\n1. 데이터셋 확인\n- 1.1 Null data check\n- 1.2 Target label 확인\n2. Exploratory data analysis\n- 2.1 Pclass\n- 2.2 Sex\n- 2.3 Both Sex and Pclass\n- 2.4 Age\n- 2.5 Pclass, Sex, Age\n- 2.6 Embarked\n- 2.7 Family - SibSp(형제 자매) + Parch(부모, 자녀)\n- 2.8 Cabin","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn')\nsns.set(font_scale=2.5) # 이 두 줄은 본 필자가 항상 쓰는 방법이다. matplotlib의 기본 scheme 말고 seaborn scheme을 세팅하고, 일일이 graph의 font size를 지정할 필요 없이 seaborn의 font_scale을 사용하면 편하다.\n\nimport missingno as msno\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:50.919635Z","iopub.execute_input":"2022-01-20T13:31:50.920526Z","iopub.status.idle":"2022-01-20T13:31:52.071258Z","shell.execute_reply.started":"2022-01-20T13:31:50.920483Z","shell.execute_reply":"2022-01-20T13:31:52.070399Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXgPmJ%2FbtqyRNzEs5v%2FoEuIJgkbIjCkgutPKwBCSk%2Fimg.png)  \n\n>missingno\n- missingno는 결측치를 파악하는데 직관적인 도움을 주는 패키지다.  \n\n>%matplotlib inline\n- IPython에서 제공하는 Rich output에 대한 표현 방식 (Rich output : 그림, 소리, 애니메이션 등)\n- notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해준다.","metadata":{}},{"cell_type":"markdown","source":"앞으로 우리가 해야할 프로세스는 대략 아래와 같다.\n1. 데이터셋 확인 - 대부분의 캐글 데이터들은 잘 정제되어 있다. 하지만 가끔 null data가 존재한다. 이를 확인하고, 향후 수정한다. \n2. 탐색적 데이터 분석(exploratory data analysis) - 여러 feature들을 개별적으로 분석하고, feature들 간의 상관관계를 확인한다. 여러 시각화 툴을 사용해 insight를 얻는다. \n3. feature engineering - 모델을 세우기에 앞서, 모델의 성능을 높일 수 있도록 feature들을 engineering한다. ont-hot encoding, class로 나누기, 구간으로 나누기, 텍스트 데이터 처리 등을 한다.\n4. model 만들기 - sklearn을 사용해 모델을 만든다. 파이썬에서 머신 러닝을 할 때는 sklearn을 사용하면 수많은 알고리즘을 일관된 문법으로 사용할 수 있다. 물론 딥러닝을 위해 tensorflow, pytorch 등을 사용할 수도 있다. \n5. 모델 학습 및 예측 - trainset을 가지고 모델을 학습시킨 후, testset을 가지고 prediction한다. \n6. 모델 평가 - 예측 성능이 원하는 수준인지 판단한다. 풀려는 문제에 따라 모델을 평가하는 방식도 달라진다. 학습된 모델이 어떤 것을 학습하였는지 확인해본다.   \n\n<br>\n\n## 1. Dataset 확인\n- 파이썬에서 테이블화 된 데이터를 다루는 데 가장 최적화되어 있으며, 많이 쓰이는 라이브러리는 pandas다. \n- 우리는 pandas를 사용해 데이터셋의 간단한 통계적 분석부터, 복잡한 처리들을 간단한 메소드를 사용해 해낼 수 있다. \n- 파이썬으로 데이터분석을 한다고 하면 반드시 능숙해져야 할 라이브러리이니, 여러 커널들을 공부하면서 사용법에 익숙해지도록 반복하자. \n- 캐글에서 데이터셋은 보통 train, testset으로 나뉘어 있다. ","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/titanic/train.csv')\ndf_test = pd.read_csv('../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.073120Z","iopub.execute_input":"2022-01-20T13:31:52.073394Z","iopub.status.idle":"2022-01-20T13:31:52.109641Z","shell.execute_reply.started":"2022-01-20T13:31:52.073362Z","shell.execute_reply":"2022-01-20T13:31:52.108840Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.111164Z","iopub.execute_input":"2022-01-20T13:31:52.111789Z","iopub.status.idle":"2022-01-20T13:31:52.136842Z","shell.execute_reply.started":"2022-01-20T13:31:52.111753Z","shell.execute_reply":"2022-01-20T13:31:52.136201Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.138384Z","iopub.execute_input":"2022-01-20T13:31:52.138939Z","iopub.status.idle":"2022-01-20T13:31:52.184657Z","shell.execute_reply.started":"2022-01-20T13:31:52.138902Z","shell.execute_reply":"2022-01-20T13:31:52.183778Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.185654Z","iopub.execute_input":"2022-01-20T13:31:52.185880Z","iopub.status.idle":"2022-01-20T13:31:52.214922Z","shell.execute_reply.started":"2022-01-20T13:31:52.185829Z","shell.execute_reply":"2022-01-20T13:31:52.214354Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"- 테이블에서 보다시피, PassengerID 숫자와 다른, 그러니까 null data가 존재하는 열(feature)가 있는 것 같다. \n- 이를 좀 더 보기 편하도록 그래프로 시각화해서 살펴보자.","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Null data check","metadata":{}},{"cell_type":"code","source":"for col in df_train.columns:\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_train[col].isnull().sum() / df_train[col].shape[0]))\n    print(msg)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.216081Z","iopub.execute_input":"2022-01-20T13:31:52.216804Z","iopub.status.idle":"2022-01-20T13:31:52.230799Z","shell.execute_reply.started":"2022-01-20T13:31:52.216754Z","shell.execute_reply":"2022-01-20T13:31:52.229752Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for col in df_test.columns:\n    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (df_test[col].isnull().sum() / df_test[col].shape[0]))\n    print(msg)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.232065Z","iopub.execute_input":"2022-01-20T13:31:52.232549Z","iopub.status.idle":"2022-01-20T13:31:52.244374Z","shell.execute_reply.started":"2022-01-20T13:31:52.232516Z","shell.execute_reply":"2022-01-20T13:31:52.243589Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"- Train, Test set에서 Age(둘 다 약 20%), Cabin(둘 다 약 80%), Embarked(Train만 0.22%), null data 존재하는 것을 볼 수 있다. \n- MSNO라는 라이브러리를 사용하면 null data의 존재를 더 쉽게 볼 수 있다. ","metadata":{}},{"cell_type":"code","source":"msno.matrix(df=df_train.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.245526Z","iopub.execute_input":"2022-01-20T13:31:52.246078Z","iopub.status.idle":"2022-01-20T13:31:52.722754Z","shell.execute_reply.started":"2022-01-20T13:31:52.246028Z","shell.execute_reply":"2022-01-20T13:31:52.722005Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"msno.bar(df=df_train.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:52.724329Z","iopub.execute_input":"2022-01-20T13:31:52.724626Z","iopub.status.idle":"2022-01-20T13:31:53.773988Z","shell.execute_reply.started":"2022-01-20T13:31:52.724585Z","shell.execute_reply":"2022-01-20T13:31:53.773150Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"msno.bar(df=df_test.iloc[:, :], figsize=(8, 8), color=(0.8, 0.5, 0.2))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:53.777761Z","iopub.execute_input":"2022-01-20T13:31:53.778002Z","iopub.status.idle":"2022-01-20T13:31:54.497317Z","shell.execute_reply.started":"2022-01-20T13:31:53.777972Z","shell.execute_reply":"2022-01-20T13:31:54.496369Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Target label 확인\n- target label이 어떤 distribution(분포)을 가지고 있는지 확인해봐야 한다. \n- 지금 같은 binary classification 문제의 경우에서, 1과 0의 분포가 어떠냐에 따라 모델의 평가 방법이 달라질 수 있다.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\n\ndf_train['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\nax[0].set_title('Pie plot - Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived', data=df_train, ax=ax[1])\nax[1].set_title('Count plot - Survived')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:54.498803Z","iopub.execute_input":"2022-01-20T13:31:54.499183Z","iopub.status.idle":"2022-01-20T13:31:54.787020Z","shell.execute_reply.started":"2022-01-20T13:31:54.499139Z","shell.execute_reply":"2022-01-20T13:31:54.786221Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":">파이 차트 : autopct는 부채꼴 안에 표시될 숫자 형식 / explode는 부채꼴이 파이 차트의 중심에서 벗어나는 정도 설정\n- 안타깝게도 죽은 사람이 많다. \n- 38.4%가 살아남았다. \n- target label의 분포가 제법 균일(balanced)하다. 불균일한 경우, 예를 들어서 100 중 1이 99, 0이 1개인 경우에는 만약 모델이 모든 것을 1이라 해도 정확도가 99%가 나오게 된다. 0을 찾는 문제라면 이 모델은 원하는 결과를 줄 수 없게 된다. 지금 문제에서는 그렇지 않으니 계속 진행하자. \n","metadata":{}},{"cell_type":"markdown","source":"## 2. Exploratory data analysis\n- 이제 본격적으로 데이터 분석을 해보자. 데이터는 매우 많다. 이 많은 데이터 안에 숨겨진 사실을 찾기 위해선 적절한 시각화가 필요하다. \n- 시각화 라이브러리는 matplotlib, seaborn, plotly 등이 있다. 특정 목적에 맞는 소스코드를 정리해 필요할 때마다 참고하면 편하다. \n<br>\n\n## 2.1 Pclass\n- 먼저 Pclass에 대해 살펴보자. Pclass는 ordinal, 서수형 데이터다. 카테고리이면서, 순서가 있는 데이터 타입이다. \n- 먼저 Pclass에 따른 생존률의 차이를 살펴보자. 엑셀의 피벗 차트와 유사한 작업을 하게 되는데, pandas dataframe에서는 groupby를 사용하면 쉽게 할 수 있다. 또한, pivot이라는 메소드가 있다. \n- 'Pclass', 'Survived'를 가져온 후, pclass로 묶는다. 그러고 나면 각 pclass마다 0, 1이 count가 되는데, 이를 평균내면 각 pclass 별 생존률이 나온다. \n- 아래와 같이 count()를 하면, 각 class에 몇 명이 있는지 확인할 수 있으며, sum()을 하면, 216명 중 생존한(survived=1) 사람의 총합을 주게 된다. ","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).count()  #as_index : 그룹을 인덱스로 지정할 것인지 여부.","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:54.788736Z","iopub.execute_input":"2022-01-20T13:31:54.789318Z","iopub.status.idle":"2022-01-20T13:31:54.802366Z","shell.execute_reply.started":"2022-01-20T13:31:54.789243Z","shell.execute_reply":"2022-01-20T13:31:54.801375Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:54.804009Z","iopub.execute_input":"2022-01-20T13:31:54.804604Z","iopub.status.idle":"2022-01-20T13:31:54.825732Z","shell.execute_reply.started":"2022-01-20T13:31:54.804572Z","shell.execute_reply":"2022-01-20T13:31:54.824992Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"- pandas의 crosstab을 사용하면 좀 더 위 과정을 좀 더 수월하게 볼 수 있다. ","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_train['Pclass'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:54.826931Z","iopub.execute_input":"2022-01-20T13:31:54.827657Z","iopub.status.idle":"2022-01-20T13:31:54.954598Z","shell.execute_reply.started":"2022-01-20T13:31:54.827622Z","shell.execute_reply":"2022-01-20T13:31:54.953726Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"- grouped 객체에 mean()을 하게 되면, 각 클래스별 생존률을 얻을 수 있다. class 1이면 아래와 같다.  \n$\\frac{80}{(80+136)}\\approx0.63$","metadata":{}},{"cell_type":"code","source":"df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:54.955971Z","iopub.execute_input":"2022-01-20T13:31:54.956389Z","iopub.status.idle":"2022-01-20T13:31:55.133488Z","shell.execute_reply.started":"2022-01-20T13:31:54.956353Z","shell.execute_reply":"2022-01-20T13:31:55.132587Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, Pclass가 좋을수록(1st) 생존률이 높은 것을 확인할 수 있다. \n- 좀 더 보기 쉽게 그래프를 그려보자. seaborn의 countplot을 이용하면, 특정 label에 따른 개수를 확인해 볼 수 있다. ","metadata":{}},{"cell_type":"code","source":"y_position = 1.02  # 타이틀이 그래프 위에 얼마나 떨어졌는지 정하는 상수 값.\nf, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train['Pclass'].value_counts().plot.bar(color=['#CD7F32', '#FFDF00', '#D3D3D3'], ax=ax[0])\nax[0].set_title('Number of Passengers By Pclass', y=y_position)\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Pclass: Survived vs Dead', y=y_position)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:55.134879Z","iopub.execute_input":"2022-01-20T13:31:55.135896Z","iopub.status.idle":"2022-01-20T13:31:55.425327Z","shell.execute_reply.started":"2022-01-20T13:31:55.135852Z","shell.execute_reply":"2022-01-20T13:31:55.424674Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"- 클래스가 높을수록, 생존 확률이 높은 것을 확인할 수 있다. Pclass 1, 2, 3 순서대로 63%, 48%, 25%다. \n- 우리는 생존에 Pclass가 큰 영향을 미친다고 생각해 볼 수 있으며, 나중에 모델을 세울 때 이 feature를 사용하는 것이 좋을 것이라 판단할 수 있다. \n<br>\n\n## 2.2 Sex\n- 이번에는 성별로 생존률이 어떻게 달라지는지 확인해보자.\n- 마찬가지로 pandas groupby와 seaborn countplot을 사용해서 시각화해보자. ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\ndf_train[['Sex', 'Survived']].groupby(['Sex'], as_index=True).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Sex: Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:55.426431Z","iopub.execute_input":"2022-01-20T13:31:55.427104Z","iopub.status.idle":"2022-01-20T13:31:55.888729Z","shell.execute_reply.started":"2022-01-20T13:31:55.427057Z","shell.execute_reply":"2022-01-20T13:31:55.887925Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, 여자가 생존할 확률이 높다.","metadata":{}},{"cell_type":"code","source":"df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:55.889875Z","iopub.execute_input":"2022-01-20T13:31:55.890114Z","iopub.status.idle":"2022-01-20T13:31:55.904047Z","shell.execute_reply.started":"2022-01-20T13:31:55.890084Z","shell.execute_reply":"2022-01-20T13:31:55.903493Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df_train['Sex'], df_train['Survived'], margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:55.904913Z","iopub.execute_input":"2022-01-20T13:31:55.905441Z","iopub.status.idle":"2022-01-20T13:31:55.959247Z","shell.execute_reply.started":"2022-01-20T13:31:55.905405Z","shell.execute_reply":"2022-01-20T13:31:55.958387Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"- Pclass와 마찬가지로, Sex도 예측 모델에 쓰일 중요한 feature임을 알 수 있다. \n<br>\n\n## 2.3 Both Sex and Pclass\n- 이번에는 Sex, Pclass 두 가지에 관하여 생존이 어떻게 달라지는지 확인해봅시다. \n- seaborn의 factorplot을 이용하면, 손쉽게 3개의 차원으로 이루어진 그래프를 그릴 수 있다. ","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', data=df_train, size=6, aspect=1.5)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:55.960724Z","iopub.execute_input":"2022-01-20T13:31:55.963604Z","iopub.status.idle":"2022-01-20T13:31:56.614921Z","shell.execute_reply.started":"2022-01-20T13:31:55.963566Z","shell.execute_reply":"2022-01-20T13:31:56.614025Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"- 모든 클래스에서 female이 살 확률이 male보다 높은 걸 알 수 있다. \n- 또한 남자, 여자 상관없이 클래스가 높을수록 살 확률이 높다.\n- 위 그래프는 hue 대신 column으로 하면 아래와 같아진다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x='Sex', y='Survived', col='Pclass', data=df_train, saturation=.5, size=9, aspect=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:56.616269Z","iopub.execute_input":"2022-01-20T13:31:56.616554Z","iopub.status.idle":"2022-01-20T13:31:57.542761Z","shell.execute_reply.started":"2022-01-20T13:31:56.616521Z","shell.execute_reply":"2022-01-20T13:31:57.541874Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Age\n- 이번에는 Age feature를 살펴보자. ","metadata":{}},{"cell_type":"code","source":"print('제일 나이 많은 탑승객 : {:.1f} Years'.format(df_train['Age'].max()))\nprint('제일 어린 탑승객 : {:.1f} Years'.format(df_train['Age'].min()))\nprint('탑승객 평균 나이 : {:.1f} Years'.format(df_train['Age'].mean()))      ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:57.544159Z","iopub.execute_input":"2022-01-20T13:31:57.544676Z","iopub.status.idle":"2022-01-20T13:31:57.551603Z","shell.execute_reply.started":"2022-01-20T13:31:57.544637Z","shell.execute_reply":"2022-01-20T13:31:57.550573Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"- 생존에 따른 Age의 histogram을 그려보자.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(9, 5))\nsns.kdeplot(df_train[df_train['Survived'] == 1]['Age'], ax=ax)\nsns.kdeplot(df_train[df_train['Survived'] == 0]['Age'], ax=ax)\nplt.legend(['Survived == 1', 'Survived == 0'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:57.553494Z","iopub.execute_input":"2022-01-20T13:31:57.553836Z","iopub.status.idle":"2022-01-20T13:31:57.877507Z","shell.execute_reply.started":"2022-01-20T13:31:57.553794Z","shell.execute_reply":"2022-01-20T13:31:57.876588Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":">sns.kdeplot : 커널 밀도 추정 (히스토그램 같은 분포)\n- 보다시피, 생존자 중 나이가 어린 경우가 많음을 볼 수 있다. ","metadata":{}},{"cell_type":"code","source":"# Age distribution withing classes\nplt.figure(figsize=(8, 6))\ndf_train['Age'][df_train['Pclass'] == 1].plot(kind='kde')\ndf_train['Age'][df_train['Pclass'] == 2].plot(kind='kde')\ndf_train['Age'][df_train['Pclass'] == 3].plot(kind='kde')\n\nplt.xlabel('Age')\nplt.title('Age Distribution within classes')\nplt.legend(['1st Class', '2nd Class', '3rd Class'])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:57.878966Z","iopub.execute_input":"2022-01-20T13:31:57.879227Z","iopub.status.idle":"2022-01-20T13:31:58.235596Z","shell.execute_reply.started":"2022-01-20T13:31:57.879196Z","shell.execute_reply":"2022-01-20T13:31:58.234746Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"- Class가 높을수록 나이 많은 사람의 비중이 커짐\n- 나이대가 변하면서 생존률이 어떻게 되는지 보려고 한다.\n- 나이 범위를 점점 넓혀가며, 생존률이 어떻게 되는지 한번 보자. ","metadata":{}},{"cell_type":"code","source":"cummulate_survival_ratio = []  # cummulate : 누적\nfor i in range(1, 80):\n    cummulate_survival_ratio.append(df_train[df_train['Age'] < i]['Survived'].sum() / len(df_train[df_train['Age'] < i]['Survived']))\n    \nplt.figure(figsize=(7, 7))\nplt.plot(cummulate_survival_ratio)\nplt.title('Survival rate change depending on range of Age', y=1.02)\nplt.ylabel('Survival rate')\nplt.xlabel('Range of Age(0~x)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:58.236890Z","iopub.execute_input":"2022-01-20T13:31:58.237189Z","iopub.status.idle":"2022-01-20T13:31:58.522983Z","shell.execute_reply.started":"2022-01-20T13:31:58.237153Z","shell.execute_reply":"2022-01-20T13:31:58.522175Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, 나이가 어릴수록 생존률이 확실히 높은 것을 확인할 수 있다. \n- 우리는 이 나이가 중요한 feature로 쓰일 수 있음을 확인했다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.5 Pclass, Sex, Age\n- 지금까지 본 Sex, Pclass, Age, Survived 모두에 대해서 보고싶다. 이를 쉽게 그려주는 것이 seaborn의  violinplot이다. \n- x축은 우리가 나눠서 보고싶어하는 case(여기선 Pclass, Sex)를 나타내고, y축은 보고 싶어하는 distribution(Age)다. \n- 한 번 그려보자.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(18, 8))\nsns.violinplot(\"Pclass\", \"Age\", hue=\"Survived\", data=df_train, scale='count', split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0, 110, 10))\nsns.violinplot(\"Sex\", \"Age\", hue=\"Survived\", data=df_train, scale='count', split=True, ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0, 110, 10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:58.524191Z","iopub.execute_input":"2022-01-20T13:31:58.524498Z","iopub.status.idle":"2022-01-20T13:31:59.076771Z","shell.execute_reply.started":"2022-01-20T13:31:58.524467Z","shell.execute_reply":"2022-01-20T13:31:59.075965Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"- 바이올린 플롯 : 중심선을 따라 대칭인 KDE 플롯이 있다. \n- 가운데 흰색 점은 중앙값(median)을 나타낸다.\n- 바이올린 중앙의 두꺼운 선은 사분위 범위를 나타낸다. \n- 바이올린 중앙의 얇은 선은 신뢰 구간을 나타낸다. (95%)\n","metadata":{}},{"cell_type":"markdown","source":"- 왼쪽 그림은 Pclass 별로 Age의 distribution이 어떻게 다른지, 거기에 생존여부에 따라 구분한 그래프다. \n- 오른쪽 그림도 마찬가지 Sex, 생존에 따른 distribution이 어떻게 다른지 보여주는 그래프다. \n- 생존만 봤을 때, 모든 클래스에서 나이가 어릴수록 생존을 많이 한 것을 볼 수 있다. \n- 오른쪽 그림에서 보면, 명확히 여자가 생존을 많이 한 것을 볼 수 있다. \n- 여성과 아이를 먼저 챙긴 것을 볼 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.6 Embarked\n- Embarked는 탑승한 항구를 나타낸다.\n- 위에서 해왔던 것과 비슷하게 탑승한 곳에 따른 생존률을 보자. ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(7, 7))\ndf_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:59.078320Z","iopub.execute_input":"2022-01-20T13:31:59.078960Z","iopub.status.idle":"2022-01-20T13:31:59.315832Z","shell.execute_reply.started":"2022-01-20T13:31:59.078924Z","shell.execute_reply":"2022-01-20T13:31:59.315064Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, 조금의 차이는 있지만 생존률은 좀 비슷한 것 같다. 그래도 C가 가장 높다.\n- 모델에 얼마나 큰 영향을 미칠지는 모르겠지만, 그래도 사용하자. \n- 사실, 모델을 만들고 나면 우리가 사용한 feature들이 얼마나 중요한 역할을 했는지 확인해 볼 수 있다. 이는 추후에 모델을 만들고 난 다음에 살펴볼 것이다. \n- 다른 feature로 split해 한 번 살펴보자.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(2, 2, figsize=(20, 15))\nsns.countplot('Embarked', data=df_train, ax=ax[0, 0])\nax[0, 0].set_title('(1) No. Of Passengers Boarded')\nsns.countplot('Embarked', hue='Sex', data=df_train, ax=ax[0, 1])\nax[0, 1].set_title('(2) Male-Female Split for Embarked')\nsns.countplot('Embarked', hue='Survived', data=df_train, ax=ax[1, 0])\nax[1, 0].set_title('(3) Embarked vs Survived')\nsns.countplot('Embarked', hue='Pclass', data=df_train, ax=ax[1, 1])\nax[1, 1].set_title('(4) Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:31:59.321328Z","iopub.execute_input":"2022-01-20T13:31:59.321656Z","iopub.status.idle":"2022-01-20T13:32:00.015124Z","shell.execute_reply.started":"2022-01-20T13:31:59.321623Z","shell.execute_reply":"2022-01-20T13:32:00.014348Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"- Figure(1) - 전체적으로 봤을 때, S에서 가장 많은 사람이 탑승했다. \n- Figure(2) - C와 Q는 남녀의 비율이 비슷하고,S는 남자가 더 많다.\n- Figrue(3) - 생존확률이 S 경우 많이 낮은 걸 볼 수 있다. \n- Figure(4) - Class로 split해서 보니, C가 생존확률이 높은 건 클래스가 높은 건 클래스가 높은 사람이 많이 타서 그렇다. S는 3rd class가 많아서 생존확률이 낮게 나온다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.7 Family - SipSp(형제 자매) + Parch(부모, 자녀)\n- SipSp와 Parch를 합하면 Family가 될 것이다. Family로 합쳐서 분석해보자. ","metadata":{}},{"cell_type":"code","source":"df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1  # 자신을 포함해야하니 1을 더한다.\ndf_test['FamilySize'] = df_test['SibSp'] +df_test['Parch'] + 1  # 자신을 포함해야하니 1을 더한다. ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:32:36.992073Z","iopub.execute_input":"2022-01-20T13:32:36.993319Z","iopub.status.idle":"2022-01-20T13:32:37.001440Z","shell.execute_reply.started":"2022-01-20T13:32:36.993254Z","shell.execute_reply":"2022-01-20T13:32:37.000360Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(\"Maximum size of Family: \", df_train['FamilySize'].max())\nprint(\"Minimum size of Family: \", df_train['FamilySize'].min())","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:33:23.312268Z","iopub.execute_input":"2022-01-20T13:33:23.313526Z","iopub.status.idle":"2022-01-20T13:33:23.320923Z","shell.execute_reply.started":"2022-01-20T13:33:23.313469Z","shell.execute_reply":"2022-01-20T13:33:23.320222Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- FamliySize와 생존의 관계를 한 번 살펴보자. ","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(1, 3, figsize=(40, 10))\nsns.countplot('FamilySize', data=df_train, ax=ax[0])\nax[0].set_title('(1) No. Of Passengers Boarded', y=1.02)\n\nsns.countplot('FamilySize', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('(2) Survived countplot depending on FamilySize', y=1.02)\n\ndf_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=True).mean().sort_values(by='Survived', ascending=False).plot.bar(ax=ax[2])\nax[2].set_title('(3) Survived rate depending on FamilySize', y=1.02)\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)  # 서브 플롯 간의 간격 조정\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:38:25.597609Z","iopub.execute_input":"2022-01-20T13:38:25.597921Z","iopub.status.idle":"2022-01-20T13:38:26.306070Z","shell.execute_reply.started":"2022-01-20T13:38:25.597889Z","shell.execute_reply":"2022-01-20T13:38:26.305380Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"- Figure (1) - 가족 크기가 1-11까지 있음을 볼 수 있다. 대부분 1명이고 그 다음으로 2, 3, 4명이다. \n- Figure (2), (3) - 가족 크기에 다른 생존비교다. 가족이 4명인 경우가 생존확률이 높다. 가족 수가 많아질수록, (5, 6, 7, 8, 11) 생존 확률이 낮아진다. 가족 수가 너무 작아도(1), 너무 커도(5, 6, 8, 11) 생존 확률이 작다. 3~4명 선에서 생존확률이 높은 걸 확인할 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.8 Fare\n- Fare는 탑승요금이며, continuous feature다. 한 번 histogram을 그려보자. ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:51:17.052168Z","iopub.execute_input":"2022-01-20T13:51:17.053158Z","iopub.status.idle":"2022-01-20T13:51:17.476721Z","shell.execute_reply.started":"2022-01-20T13:51:17.053091Z","shell.execute_reply":"2022-01-20T13:51:17.475880Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, distribution이 매우 비대칭인 것을 알 수 있다. (high skewness) 만약 이대로 모델에 넣어준다면 자칫 모델이 잘못 학습할 수도 있다. 몇 개 없는 outlier에 대해서 너무 민감하게 반응한다면, 실제 예측 시에 좋지 못한 결과를 부를 수 있다. \n- outlier의 영향을 줄이기 위해 Fare에 log를 취한다. \n- 여기서 우리는 pandas의 유용한 기능을 사용할 것이다. DataFrame의 특정 columns에 공통된 작업(함수)를 적용하고 싶으면, 아래의 map, 또는 apply를 사용하면 매우 손쉽게 적용할 수 있다. \n- 우리가 지금 원하는 것은 Fare columns의 데이터 모두를 log 값 취하는 것인데, 파이썬의 간단한 lambda 함수를 이용해 간단한 로그를 적용하는 함수를 map에 인수로 넣어주면, Fare columns 데이터에 그대로 적용된다. 매우 유용한 기능이니 꼭 숙지하자!","metadata":{}},{"cell_type":"code","source":"# 아래 줄은 뒤늦게 발견했다. 13번째 강의에 언급되니, 일단 따라치고 넘어가면 된다.\ndf_test.loc[df_test.Fare.isnull(), 'Fare'] = df_test['Fare'].mean()  # testset에 있는 nan value를 평균값으로 치환한다.\n\ndf_train['Fare'] = df_train['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\ndf_test['Fare'] = df_test['Fare'].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T13:59:41.711095Z","iopub.execute_input":"2022-01-20T13:59:41.712051Z","iopub.status.idle":"2022-01-20T13:59:41.725487Z","shell.execute_reply.started":"2022-01-20T13:59:41.711970Z","shell.execute_reply":"2022-01-20T13:59:41.724420Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sns.distplot(df_train['Fare'], color='b', label='Skewness : {:.2f}'.format(df_train['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:00:52.404256Z","iopub.execute_input":"2022-01-20T14:00:52.404810Z","iopub.status.idle":"2022-01-20T14:00:52.797868Z","shell.execute_reply.started":"2022-01-20T14:00:52.404770Z","shell.execute_reply":"2022-01-20T14:00:52.796840Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"- log를 취하니, 이제 비대칭성이 많이 사라진 것을 볼 수 있다. \n- 우리는 이런 작업을 사용해 모델이 좀 더 좋은 성능을 내도록 할 수 있다. \n- 사실 방금한 것은 feature engineering에 들어가는 부분인데, 여기서 작업했다.\n- 모델을 학습시키기위해, 그리고 그 모델의 성능을 높이기 위해 feature들에 여러 조작을 가하거나, 새로운 feature를 추가하는 것을 feature engineering이라고 하는데, 우리는 이제 그것을 살펴볼 것이다. ","metadata":{}},{"cell_type":"markdown","source":"## 2.9 Cabin\n- 이 feature는 NaN이 대략 80%이므로, 생존에 영향을 미칠 중요한 정보를 얻어내기가 쉽지는 않다. \n- 그러므로 우리가 세우려는 모델에 포함시키지 않도록 하자. ","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:04:41.309400Z","iopub.execute_input":"2022-01-20T14:04:41.309799Z","iopub.status.idle":"2022-01-20T14:04:41.329911Z","shell.execute_reply.started":"2022-01-20T14:04:41.309758Z","shell.execute_reply":"2022-01-20T14:04:41.328919Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## 2.10 Ticket\n- 이 feature는 NaN은 없다. 일단 string data이므로 우리가 어떤 작업들을 해주어야 실제 모델에 사용할 수 있는데, 이를 위해선 사실 아이디어가 필요하다. ","metadata":{}},{"cell_type":"code","source":"df_train['Ticket'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:06:30.720508Z","iopub.execute_input":"2022-01-20T14:06:30.720787Z","iopub.status.idle":"2022-01-20T14:06:30.732193Z","shell.execute_reply.started":"2022-01-20T14:06:30.720757Z","shell.execute_reply":"2022-01-20T14:06:30.731089Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"- 보다시피, ticket number는 매우 다양하다. 우리는 여기서 어떤 특징을 이끌어내서 생존과 연결시킬 수 있을까?\n- 여러분이 직접 아이디어를 내보자. 이것이 본격적인 캐글 레이스의 시작점이다. \n- 이 튜토리얼에서는 튜토리얼이니 일단 ticket은 넘기도록 하자. 튜토리얼을 끝낸 후, 여러분의 모델의 성능을 향상시키기 위해 ticket에서 정보를 이끌어내는 것도 좋겠다. \n- 본 튜토리얼은 https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python, https://www.kaggle.com/startupsci/titanic-data-science-solutions, https://www.kaggle.com/ash316/eda-to-prediction-dietanic, https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling 을 참고해 만들었다. 공유해준 캐글러께 감사드린다. ","metadata":{}}]}